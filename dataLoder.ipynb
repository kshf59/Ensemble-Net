{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f271b9d-c9a3-41c5-a2e5-cd21dc79d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "from evaluate import evaluate\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from collections import OrderedDict\n",
    "\n",
    "#from model.unet.unet_model import UNet\n",
    "#from model.segnet.segnet_model import SegNet\n",
    "#from torchvision.models.segmentation import deeplabv3_resnet101 as DeepLabv3\n",
    "from model.ensemblenet_model import EnsembleNet\n",
    "\n",
    "\n",
    "from utils.dice_score import dice_loss\n",
    "from utils.data_load import KittiDataset\n",
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ae7ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Val_Percent = 0.3\n",
    "Scale_Percent = 1.0\n",
    "Batch_Size = 8\n",
    "learning_rate = 0.0001\n",
    "Pin_Memory = False\n",
    "epochs = 30\n",
    "\n",
    "#Image_Size = [384, 1242]\n",
    "Image_Size = [384, 1216]\n",
    "#Image_Size = [384,384]\n",
    "Gradient_Clipping = 0.8\n",
    "\n",
    "#Num_Class = 31\n",
    "#Num_Class = 21\n",
    "Num_Class = 2\n",
    "Num_Channel = 3\n",
    "amp = True\n",
    "\n",
    "Model_Name = 'ensemble_voting'\n",
    "\n",
    "\n",
    "Img_Path =  'data/data_road/training/image_2'\n",
    "Mask_Path =  'data/data_road/training/semantic'\n",
    "\n",
    "save_checkpoint = False\n",
    "checkpoint_dir = '../trained'\n",
    "batch_size = Batch_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567f8440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirImg = Path(Img_Path)\n",
    "dirMask = Path(Mask_Path)\n",
    "\n",
    "dir_checkpoint = Path(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67210d1-7567-4b7d-858b-349748c428a0",
   "metadata": {},
   "source": [
    "train_transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=30, p=0.5),\n",
    "        #A.RandomBrightnessContrast(p=0.5),\n",
    "        #A.RandomGamma(p=0.5),\n",
    "        #A.RandomSnow(p=0.5),\n",
    "        #A.RandomRain(p=0.5),\n",
    "        #A.RandomFog(p=0.5),\n",
    "        #A.RandomSunFlare(p=0.5),\n",
    "        A.RandomShadow(p=0.5),\n",
    "        #A.RandomToneCurve(p=0.5),\n",
    "        #A.GaussNoise(p=0.5),\n",
    "        #A.Emboss(p=0.5),  # IAAEmboss 대신 Emboss 사용\n",
    "        #A.Perspective(p=0.5),  # IAAPerspective 대신 Perspective 사용\n",
    "        #A.CLAHE(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8e3825-8747-4f49-b3ee-eac27522ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4a35b2-bc69-49e4-b17c-e850f278473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 289/289 [00:00<00:00, 841.24it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets =  KittiDataset(dirImg, dirMask, Image_Size, Scale_Percent)\n",
    "#datasets =  KittiDataset(dirImg, dirMask, Image_Size, Scale_Percent, train_transform)\n",
    "n_val = int(len(datasets) * Val_Percent)\n",
    "n_train = len(datasets) - n_val\n",
    "train_set, val_set = random_split(datasets, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "loader_args = dict(batch_size=Batch_Size, num_workers= os.cpu_count(), pin_memory=Pin_Memory)\n",
    "train_loader = DataLoader(train_set, shuffle=True, drop_last = True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b36f40-c709-4e1e-b4f6-66a1954edfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnsembleNet(Model_Name, Num_Channel, Num_Class)\n",
    "model = model.to(memory_format=torch.channels_last, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a29bc96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "\n",
    "if 'ensemble_voting' in Model_Name:\n",
    "    unet_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    segnet_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    enet_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    voting_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    \n",
    "else:\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e43754-2870-4837-b38a-3f57d6733ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(pred, true_masks, nclass, multiclass):\n",
    "    loss = criterion(pred, true_masks)\n",
    "    loss += dice_loss(\n",
    "        F.softmax(pred, dim=1).float(),\n",
    "        F.one_hot(true_masks, nclass).permute(0, 3, 1, 2).float(),\n",
    "        multiclass=multiclass\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def forward_and_backward(model, images, true_masks, amp, optimizer, grad_scaler, model_name):\n",
    "    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "        if model_name == 'ensemble_voting':\n",
    "            unet_pred, segnet_pred, enet_pred = model(images)\n",
    "            #deeplab_pred = deeplab_pred['out']\n",
    "        else:\n",
    "            masks_pred = model(images)\n",
    "            if isinstance(masks_pred, OrderedDict):\n",
    "                masks_pred = masks_pred['out']\n",
    "\n",
    "        try:\n",
    "            mn_cls = model.n_classes\n",
    "        except:\n",
    "            mn_cls = model.classifier[-1].out_channels\n",
    "\n",
    "\n",
    "        if model_name == 'ensemble_voting':\n",
    "            unet_loss = calculate_loss(unet_pred, true_masks, mn_cls, multiclass=True)\n",
    "            segnet_loss = calculate_loss(segnet_pred, true_masks, mn_cls, multiclass=True)\n",
    "            enet_loss = calculate_loss(enet_pred, true_masks, mn_cls, multiclass=True)\n",
    "            \n",
    "        else:\n",
    "            loss = calculate_loss(masks_pred, true_masks, mn_cls, multiclass=True)\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    if model_name == 'ensemble_voting':\n",
    "        for pred, loss in zip([unet_pred, segnet_pred, enet_pred], [unet_loss, segnet_loss, enet_loss]):\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), Gradient_Clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "        \n",
    "        return model, unet_loss, segnet_loss, enet_loss\n",
    "    else:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), Gradient_Clipping)\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "        \n",
    "        return model, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb76263-8fd8-437d-9204-8ebc2af3de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 15.25img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Unet Loss: 0.32835644483566284     Segnet Loss: 0.492887407541275     Enet Loss: 0.4775274693965912\n",
      "Voting Loss: 0.9804196755091349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:20<00:00,  9.66img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Unet Validation Dice Score: 0.29782700538635254     Segnet Validation Dice Score: 0.6778470873832703     Enet Validation Dice Score: 0.11035852879285812\n",
      "Ensemble Voting Validation Dice Score: 0.663628876209259 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:14<00:00, 14.93img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "Unet Loss: 0.1588941514492035     Segnet Loss: 0.22278134524822235     Enet Loss: 0.29560279846191406\n",
      "Voting Loss: 0.4802097628513972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:18<00:00, 10.90img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Unet Validation Dice Score: 0.700282633304596     Segnet Validation Dice Score: 0.7329278588294983     Enet Validation Dice Score: 0.49273139238357544\n",
      "Ensemble Voting Validation Dice Score: 0.7260976433753967 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  47%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 96/203 [00:08<00:09, 11.78img/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2410304/2491091583.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_and_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel_Name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2410304/2224334880.py\u001b[0m in \u001b[0;36mforward_and_backward\u001b[0;34m(model, images, true_masks, amp, optimizer, grad_scaler, model_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'mps'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ensemble_voting'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0munet_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegnet_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menet_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m#deeplab_pred = deeplab_pred['out']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ksh/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ksh/Ensemble-Net/model/ensemblenet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0munet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0msegnet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0menet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0munet_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegnet_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menet_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ksh/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ksh/Ensemble-Net/model/Enet/enet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Stage 1 - Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mstage1_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_indices1_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample1_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregular1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregular1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ksh/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ksh/Ensemble-Net/model/Enet/enet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# convert padding accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Concatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valScore_list1 = []\n",
    "TrainLoss_list1 = []\n",
    "\n",
    "valScore_list2 = []\n",
    "TrainLoss_list2 = []\n",
    "\n",
    "valScore_list3 = []\n",
    "TrainLoss_list3 = []\n",
    "\n",
    "valScore_list4 = []\n",
    "TrainLoss_list4 = []\n",
    "\n",
    "# 5. Begin training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_unet_loss = 0\n",
    "    epoch_segnet_loss = 0\n",
    "    epoch_enet_loss = 0\n",
    "    epoch_voting_loss = 0\n",
    "    \n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            images, true_masks = batch['image'], batch['mask']\n",
    "\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                \n",
    "            result = forward_and_backward(model, images, true_masks, amp, optimizer, grad_scaler, Model_Name)\n",
    "            \n",
    "            if len(result) == 4:\n",
    "                model, unet_loss, segnet_loss, enet_loss = result\n",
    "                \n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_unet_loss += unet_loss.item()\n",
    "                epoch_segnet_loss += segnet_loss.item()\n",
    "                epoch_enet_loss += enet_loss.item()\n",
    "                vot_loss = ((unet_loss.item() + segnet_loss.item() + enet_loss.item()) /3)\n",
    "                epoch_voting_loss += vot_loss\n",
    "                \n",
    "                \n",
    "            elif len(result) == 2:\n",
    "                model, loss = result\n",
    "                \n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "        print('***')\n",
    "        if len(result) == 4:\n",
    "            print('Unet Loss: {}     Segnet Loss: {}     Enet Loss: {}'.format(unet_loss, segnet_loss, enet_loss))\n",
    "            print('Voting Loss: {}'.format(vot_loss))\n",
    "            \n",
    "            \n",
    "        elif len(result) == 2:\n",
    "            print('{} Loss: {}'.format(Model_Name, loss))\n",
    "\n",
    "        # Evaluation round\n",
    "        division_step = (n_train // (5 * batch_size))\n",
    "        if division_step > 0:\n",
    "            #if global_step % division_step == 0:\n",
    "            if len(result) == 4:\n",
    "                unet_val_score, segnet_val_score, enet_val_score, voting_val_score = evaluate(model, val_loader, device, Model_Name, amp)\n",
    "                \n",
    "                unet_scheduler.step(unet_val_score)\n",
    "                segnet_scheduler.step(segnet_val_score)\n",
    "                enet_scheduler.step(enet_val_score)\n",
    "                voting_scheduler.step(voting_val_score)\n",
    "                \n",
    "                valScore_list1.append(unet_val_score)\n",
    "                TrainLoss_list1.append(unet_loss)\n",
    "                valScore_list2.append(segnet_val_score)\n",
    "                TrainLoss_list2.append(segnet_loss)                \n",
    "                valScore_list3.append(enet_val_score)\n",
    "                TrainLoss_list3.append(enet_loss)\n",
    "                valScore_list4.append(voting_val_score)\n",
    "                TrainLoss_list4.append(vot_loss)\n",
    "                \n",
    "                print('---')\n",
    "                print('Unet Validation Dice Score: {}     Segnet Validation Dice Score: {}     Enet Validation Dice Score: {}'.format(unet_val_score, segnet_val_score, enet_val_score))\n",
    "                print('Ensemble Voting Validation Dice Score: {} '.format(voting_val_score))\n",
    "                \n",
    "            else:\n",
    "                val_score = evaluate(model, val_loader, device, Model_Name, amp)\n",
    "                \n",
    "                scheduler.step(val_score)\n",
    "                print('---')\n",
    "                print('{} Validation Dice Score: {}'.format(Model_Name, val_score))\n",
    "            \n",
    "                valScore_list1.append(val_score)\n",
    "                TrainLoss_list1.append(loss)\n",
    "\n",
    "                #valScore_list.append(val_score)\n",
    "                #TrainLoss_list.append(loss)\n",
    "                #print('Validation Dice score: {}'.format(val_score))\n",
    "                                \n",
    "        \n",
    "    if save_checkpoint:\n",
    "        Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99605d78-81dd-415e-a757-7e3e8ff8e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80c043c5-eeea-4b65-aef8-3f083f6a65b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7288, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02024f4-5520-4e80-b5e2-1c0f7d4ad10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53bea0-5bf5-4a51-abe0-34c525c54a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e0b26-2f49-4d4c-9ca3-4abb3a4e7d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab8d26-fca2-4e31-b3ed-4be2e3df242f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksh",
   "language": "python",
   "name": "ksh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
