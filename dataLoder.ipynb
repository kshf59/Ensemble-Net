{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f271b9d-c9a3-41c5-a2e5-cd21dc79d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "from evaluate import evaluate\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from collections import OrderedDict\n",
    "\n",
    "#from model.unet.unet_model import UNet\n",
    "#from model.segnet.segnet_model import SegNet\n",
    "#from torchvision.models.segmentation import deeplabv3_resnet101 as DeepLabv3\n",
    "from model.ensemblenet_model import EnsembleNet\n",
    "\n",
    "\n",
    "from utils.dice_score import dice_loss\n",
    "from utils.data_load import KittiDataset\n",
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ae7ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Val_Percent = 0.3\n",
    "Scale_Percent = 1.0\n",
    "Batch_Size = 8\n",
    "learning_rate = 0.0001\n",
    "Pin_Memory = False\n",
    "epochs = 10\n",
    "\n",
    "#Image_Size = [384, 1242]\n",
    "Image_Size = [384, 1216]\n",
    "#Image_Size = [384,384]\n",
    "Gradient_Clipping = 0.7\n",
    "\n",
    "#Num_Class = 31\n",
    "#Num_Class = 21\n",
    "Num_Class = 2\n",
    "Num_Channel = 3\n",
    "amp = True\n",
    "\n",
    "Model_Name = 'ensemble_voting'\n",
    "\n",
    "\n",
    "Img_Path =  'data/data_road/training/image_2'\n",
    "Mask_Path =  'data/data_road/training/semantic'\n",
    "\n",
    "save_checkpoint = False\n",
    "checkpoint_dir = '../trained'\n",
    "batch_size = Batch_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567f8440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirImg = Path(Img_Path)\n",
    "dirMask = Path(Mask_Path)\n",
    "\n",
    "dir_checkpoint = Path(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67210d1-7567-4b7d-858b-349748c428a0",
   "metadata": {},
   "source": [
    "train_transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=30, p=0.5),\n",
    "        #A.RandomBrightnessContrast(p=0.5),\n",
    "        #A.RandomGamma(p=0.5),\n",
    "        #A.RandomSnow(p=0.5),\n",
    "        #A.RandomRain(p=0.5),\n",
    "        #A.RandomFog(p=0.5),\n",
    "        #A.RandomSunFlare(p=0.5),\n",
    "        A.RandomShadow(p=0.5),\n",
    "        #A.RandomToneCurve(p=0.5),\n",
    "        #A.GaussNoise(p=0.5),\n",
    "        #A.Emboss(p=0.5),  # IAAEmboss 대신 Emboss 사용\n",
    "        #A.Perspective(p=0.5),  # IAAPerspective 대신 Perspective 사용\n",
    "        #A.CLAHE(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8e3825-8747-4f49-b3ee-eac27522ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4a35b2-bc69-49e4-b17c-e850f278473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 289/289 [00:00<00:00, 745.00it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets =  KittiDataset(dirImg, dirMask, Image_Size, Scale_Percent)\n",
    "#datasets =  KittiDataset(dirImg, dirMask, Image_Size, Scale_Percent, train_transform)\n",
    "n_val = int(len(datasets) * Val_Percent)\n",
    "n_train = len(datasets) - n_val\n",
    "train_set, val_set = random_split(datasets, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "loader_args = dict(batch_size=Batch_Size, num_workers= os.cpu_count(), pin_memory=Pin_Memory)\n",
    "train_loader = DataLoader(train_set, shuffle=True, drop_last = True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b36f40-c709-4e1e-b4f6-66a1954edfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/anaconda3/envs/ksh/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/user1/anaconda3/envs/ksh/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = EnsembleNet(Model_Name, Num_Channel, Num_Class)\n",
    "model = model.to(memory_format=torch.channels_last, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a29bc96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c12166-2599-4dc5-a2e5-4dc5af550451",
   "metadata": {},
   "source": [
    "### 아래 코드를 수정해야함~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e43754-2870-4837-b38a-3f57d6733ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(pred, true_masks, multiclass):\n",
    "    loss = criterion(pred, true_masks)\n",
    "    loss += dice_loss(\n",
    "        F.softmax(pred, dim=1).float(),\n",
    "        F.one_hot(true_masks, mn_cls).permute(0, 3, 1, 2).float(),\n",
    "        multiclass=multiclass\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def forward_and_backward(model, images, true_masks, amp, optimizer, grad_scaler, model_name):\n",
    "    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "        if model_name == 'ensemble_voting':\n",
    "            unet_pred, segnet_pred, deeplab_pred = model(images)\n",
    "            deeplab_pred = deeplab_pred['out']\n",
    "        else:\n",
    "            masks_pred = model(images)\n",
    "            if isinstance(masks_pred, OrderedDict):\n",
    "                masks_pred = masks_pred['out']\n",
    "\n",
    "    mn_cls = model.n_classes if model_name != 'ensemble_voting' else model.module.n_classes\n",
    "\n",
    "\n",
    "    if model_name == 'ensemble_voting':\n",
    "        unet_loss = calculate_loss(unet_pred, true_masks, multiclass=True)\n",
    "        segnet_loss = calculate_loss(segnet_pred, true_masks, multiclass=True)\n",
    "        deeplab_loss = calculate_loss(deeplab_pred, true_masks, multiclass=True)\n",
    "    else:\n",
    "        squ_masks_pred = masks_pred.squeeze(1) if mn_cls == 1 else masks_pred\n",
    "        loss = calculate_loss(squ_masks_pred, true_masks, multiclass=False)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    if model_name == 'ensemble_voting':\n",
    "        for pred, loss in zip([unet_pred, segnet_pred, deeplab_pred], [unet_loss, segnet_loss, deeplab_loss]):\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), Gradient_Clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "    else:\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), Gradient_Clipping)\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "    return unet_pred, segnet_pred, deeplab_pred if model_name == 'ensemble_voting' else model, loss\n",
    "\n",
    "# 사용 예시\n",
    "#result = process_model(model, images, true_masks, __amp__, optimizer, grad_scaler, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa7aa28e-d818-4dd5-a9ae-3093cf41d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(__model__, __images__, __true_masks__, __amp__, model_name):\n",
    "    \n",
    "        \n",
    "        if model_name != 'ensemble_voting':    \n",
    "            with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=__amp__):\n",
    "                masks_pred = __model__(__images__)\n",
    "                if isinstance(masks_pred, OrderedDict):\n",
    "                    masks_pred = masks_pred['out']\n",
    "\n",
    "                try:\n",
    "                    mn_cls = __model__.n_classes\n",
    "                except:\n",
    "                    mn_cls = __model__.classifier[-1].out_channels\n",
    "\n",
    "\n",
    "                if mn_cls == 1:\n",
    "\n",
    "                    squ_masks_pred = masks_pred.squeeze(1)\n",
    "                    loss = criterion(squ_masks_pred, __true_masks__.float())\n",
    "                    loss += dice_loss(F.sigmoid(squ_masks_pred), __true_masks__.float(), multiclass=False)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    loss = criterion(masks_pred, __true_masks__)\n",
    "                    loss += dice_loss(\n",
    "                        F.softmax(masks_pred, dim=1).float(),\n",
    "                        F.one_hot(__true_masks__, mn_cls).permute(0, 3, 1, 2).float(),\n",
    "                        multiclass=True\n",
    "                    )\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(__model__.parameters(), Gradient_Clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "            return model, loss\n",
    "\n",
    "        elif model_name == 'ensemble_voting':\n",
    "            with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=__amp__):\n",
    "                \n",
    "                __unet_pred__, __segnet_pred__, __deeplab_pred__ = __model__(__images__)\n",
    "                __deeplab_pred__ = __deeplab_pred__['out']\n",
    "                \n",
    "                mn_cls = __model__.n_classes\n",
    "                \n",
    "\n",
    "                __unet_loss__ = criterion(__unet_pred__, __true_masks__)\n",
    "                __unet_loss__ += dice_loss(\n",
    "                        F.softmax(__unet_pred__, dim=1).float(),\n",
    "                        F.one_hot(__true_masks__, mn_cls).permute(0, 3, 1, 2).float(),\n",
    "                        multiclass=True )        \n",
    "\n",
    "                __segnet_loss__ = criterion(__segnet_pred__, __true_masks__)\n",
    "                __segnet_loss__ += dice_loss(\n",
    "                        F.softmax(__segnet_pred__, dim=1).float(),\n",
    "                        F.one_hot(__true_masks__, mn_cls).permute(0, 3, 1, 2).float(),\n",
    "                        multiclass=True )\n",
    "\n",
    "                __deeplab_loss__ = criterion(__deeplab_pred__, __true_masks__)\n",
    "                __deeplab_loss__ += dice_loss(\n",
    "                            F.softmax(__deeplab_pred__, dim=1).float(),\n",
    "                            F.one_hot(__true_masks__, mn_cls).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True )\n",
    "                \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(__unet_loss__).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(__model__.parameters(), Gradient_Clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()   \n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(__segnet_loss__).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(__model__.parameters(), Gradient_Clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update() \n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(__deeplab_loss__).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(__model__.parameters(), Gradient_Clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()   \n",
    "\n",
    "            return __unet_pred__, __segnet_pred__, __deeplab_pred__, __unet_loss__, __segnet_loss__, __deeplab_loss__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24cc3b67-48f7-41cb-a698-88d9762d21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:19<00:00, 10.26img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.39075762033462524\n",
      "Training segnet Loss: 0.7669399976730347\n",
      "Training deelab Loss: 0.4201391637325287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:16<00:00, 11.77img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.46772128343582153\n",
      "Training segnet Loss: 0.4714847207069397\n",
      "Training deelab Loss: 0.25792646408081055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.59img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.31488171219825745\n",
      "Training segnet Loss: 0.37598085403442383\n",
      "Training deelab Loss: 0.1507311463356018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.67img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.25888592004776\n",
      "Training segnet Loss: 0.2539902329444885\n",
      "Training deelab Loss: 0.11260766535997391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.61img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.19529318809509277\n",
      "Training segnet Loss: 0.2128198742866516\n",
      "Training deelab Loss: 0.07078924030065536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.62img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.197230726480484\n",
      "Training segnet Loss: 0.1467919647693634\n",
      "Training deelab Loss: 0.05753321200609207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.62img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.23459337651729584\n",
      "Training segnet Loss: 0.1928694248199463\n",
      "Training deelab Loss: 0.051108039915561676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.58img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.2397838532924652\n",
      "Training segnet Loss: 0.21610693633556366\n",
      "Training deelab Loss: 0.04417917877435684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.61img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.1764993965625763\n",
      "Training segnet Loss: 0.13347478210926056\n",
      "Training deelab Loss: 0.035884156823158264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 200/203 [00:17<00:00, 11.50img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training unet Loss: 0.15233871340751648\n",
      "Training segnet Loss: 0.11093688011169434\n",
      "Training deelab Loss: 0.0344683937728405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valScore_list = []\n",
    "TrainLoss_list = []\n",
    "# 5. Begin training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            images, true_masks = batch['image'], batch['mask']\n",
    "\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            '''\n",
    "            with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                \n",
    "                masks_pred = model(images)\n",
    "                if isinstance(masks_pred, OrderedDict):\n",
    "                    masks_pred = masks_pred['out']\n",
    "                             \n",
    "                try:\n",
    "                    mn_cls = model.n_classes\n",
    "                except:\n",
    "                    mn_cls = model.classifier[-1].out_channels\n",
    "                    \n",
    "                \n",
    "                if mn_cls == 1:\n",
    "                    \n",
    "                    squ_masks_pred = masks_pred.squeeze(1)\n",
    "                    loss = criterion(squ_masks_pred, true_masks.float())\n",
    "                    loss += dice_loss(F.sigmoid(squ_masks_pred), true_masks.float(), multiclass=False)\n",
    "                    \n",
    "                    #loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "                    #loss += dice_loss(masks_pred, true_masks, multiclass=False)\n",
    "                    \n",
    "                else:\n",
    "                    loss = criterion(masks_pred, true_masks)\n",
    "                    loss += dice_loss(\n",
    "                        F.softmax(masks_pred, dim=1).float(),\n",
    "                        F.one_hot(true_masks, mn_cls).permute(0, 3, 1, 2).float(),\n",
    "                        multiclass=True\n",
    "                    )\n",
    "                \n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), Gradient_Clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            \n",
    "            #model, loss = train_model(model, images, true_masks, amp, Model_Name)\n",
    "            \n",
    "            unet_model, segnet_model, deeplab_model, unet_loss, segnet_loss, deeplab_loss = train_model(model, images, true_masks, amp, Model_Name)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(images.shape[0])\n",
    "            global_step += 1\n",
    "            #epoch_loss += loss.item()\n",
    "            \n",
    "        print('Training unet Loss: {}'.format(unet_loss))\n",
    "        print('Training segnet Loss: {}'.format(segnet_loss))\n",
    "        print('Training deelab Loss: {}'.format(deeplab_loss))\n",
    "            \n",
    "        '''\n",
    "            # Evaluation round\n",
    "            division_step = (n_train // (5 * batch_size))\n",
    "            if division_step > 0:\n",
    "                if global_step % division_step == 0:\n",
    "\n",
    "                    val_score = evaluate(model, val_loader, device, amp)\n",
    "                    \n",
    "                    scheduler.step(val_score)\n",
    "                    valScore_list.append(val_score)\n",
    "                    TrainLoss_list.append(loss)\n",
    "                    \n",
    "\n",
    "                    #logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                    print('Training Dice Loss: {}'.format(loss))\n",
    "                    print('Validation Dice score: {}'.format(val_score))\n",
    "                                \n",
    "        '''\n",
    "    if save_checkpoint:\n",
    "        Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81128a37-98a3-4f07-a93f-6866ea42f5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.4461, device='cuda:0'),\n",
       " tensor(0.7066, device='cuda:0'),\n",
       " tensor(0.7842, device='cuda:0'),\n",
       " tensor(0.7259, device='cuda:0'),\n",
       " tensor(0.7876, device='cuda:0'),\n",
       " tensor(0.8873, device='cuda:0'),\n",
       " tensor(0.9105, device='cuda:0'),\n",
       " tensor(0.8723, device='cuda:0'),\n",
       " tensor(0.9304, device='cuda:0'),\n",
       " tensor(0.9438, device='cuda:0'),\n",
       " tensor(0.9486, device='cuda:0'),\n",
       " tensor(0.9297, device='cuda:0'),\n",
       " tensor(0.9496, device='cuda:0'),\n",
       " tensor(0.9369, device='cuda:0'),\n",
       " tensor(0.9490, device='cuda:0'),\n",
       " tensor(0.9288, device='cuda:0'),\n",
       " tensor(0.9442, device='cuda:0'),\n",
       " tensor(0.9550, device='cuda:0'),\n",
       " tensor(0.9571, device='cuda:0'),\n",
       " tensor(0.9579, device='cuda:0'),\n",
       " tensor(0.9598, device='cuda:0'),\n",
       " tensor(0.9610, device='cuda:0'),\n",
       " tensor(0.9620, device='cuda:0'),\n",
       " tensor(0.9627, device='cuda:0'),\n",
       " tensor(0.9636, device='cuda:0'),\n",
       " tensor(0.9634, device='cuda:0'),\n",
       " tensor(0.9643, device='cuda:0'),\n",
       " tensor(0.9641, device='cuda:0'),\n",
       " tensor(0.9634, device='cuda:0'),\n",
       " tensor(0.9640, device='cuda:0'),\n",
       " tensor(0.9645, device='cuda:0'),\n",
       " tensor(0.9640, device='cuda:0'),\n",
       " tensor(0.9641, device='cuda:0'),\n",
       " tensor(0.9638, device='cuda:0'),\n",
       " tensor(0.9640, device='cuda:0'),\n",
       " tensor(0.9636, device='cuda:0'),\n",
       " tensor(0.9644, device='cuda:0'),\n",
       " tensor(0.9642, device='cuda:0'),\n",
       " tensor(0.9643, device='cuda:0'),\n",
       " tensor(0.9642, device='cuda:0'),\n",
       " tensor(0.9646, device='cuda:0'),\n",
       " tensor(0.9642, device='cuda:0'),\n",
       " tensor(0.9637, device='cuda:0'),\n",
       " tensor(0.9641, device='cuda:0'),\n",
       " tensor(0.9643, device='cuda:0'),\n",
       " tensor(0.9647, device='cuda:0'),\n",
       " tensor(0.9642, device='cuda:0'),\n",
       " tensor(0.9644, device='cuda:0'),\n",
       " tensor(0.9635, device='cuda:0'),\n",
       " tensor(0.9639, device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valScore_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2310eff5-cc1a-4017-99a9-0fc55ac9a4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.3917, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.1367, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.1151, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.2557, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0550, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0401, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0346, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0477, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0306, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0314, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0286, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0386, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0391, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0296, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0243, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0216, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0286, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0334, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0261, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0256, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0270, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0208, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0301, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0215, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0244, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0246, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0212, device='cuda:0', grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLoss_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksh",
   "language": "python",
   "name": "ksh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
